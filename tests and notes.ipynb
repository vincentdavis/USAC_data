{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "hdrs = {'User-Agent':'Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)'}\n",
    "r = requests.session()\n",
    "\n",
    "# This is the results page, Need to scrape the columns;\n",
    "# Place, Points, Name, City, State, Time, USAC#, Bib, Team\n",
    "# json is http://www.usacycling.org/results/index.php?ajax=1&act=infoid&info_id=94310\n",
    "raceresults = r.get('http://www.usacycling.org/results/index.php?year=2016&id=2', headers=hdrs)\n",
    "race = BeautifulSoup(raceresults.text, 'html.parser')\n",
    "\n",
    "# This is the details of lap times for the race. need to scrape the columns\n",
    "# Place Name Lap 1 Lap 2 Lap 3 Lap 4   each race may have different number of laps, more or less than 4\n",
    "racesplits = r.get('https://www.usacycling.org/results/index.php?ajax=1&act=loadresults&race_id=955427', headers=hdrs)\n",
    "p=json.loads(racesplits.text)['message']\n",
    "BeautifulSoup(p, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Race is: 94310 and race name is: 2016 USA Cycling Cyclo-Cross Nationals | Asheville, NC | Jan 4, 2016 - Jan 10, 2016\n",
      "---- CX Women Non-Championship 35+\n",
      "    ---- race_955340\n",
      "---- CX Women Non-Championship 23-34\n",
      "    ---- race_955341\n",
      "---- CX Men Non-Championship 30-39\n",
      "    ---- race_955342\n",
      "---- CX Men Non-Championship 23-29\n",
      "    ---- race_955343\n",
      "---- CX Men Non-Championship 50+\n",
      "    ---- race_955344\n",
      "---- CX Men Non-Championship 40-49\n",
      "    ---- race_955345\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "hdrs = {'User-Agent':'Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)'}\n",
    "r = requests.session()\n",
    "raceresults = r.get('http://www.usacycling.org/results/index.php?year=2016&id=2', headers=hdrs)\n",
    "for e in range(94310, 94311): # these are event id's\n",
    "    response = r.get('http://www.usacycling.org/results/index.php?ajax=1&act=infoid&info_id='+str(e), headers=hdrs)\n",
    "    message = json.loads(response.text)['message']\n",
    "    race = BeautifulSoup(message, 'html.parser')\n",
    "    if \"No results found.\" not in race:\n",
    "        print('Race is: {} and race name is: {}'.format(e, ' | '.join(x for x in race.find('h3').find_all(text=True))))\n",
    "        for a in race.find_all('li'):\n",
    "            print('---- {}'.format(a.find('a').contents[0])) # get the text from the href\n",
    "            print('    ---- {}'.format(a.get('id'))) # get the id tage value\n",
    "            results = r.get('https://www.usacycling.org/results/index.php?ajax=1&act=loadresults&race_id=955427', headers=hdrs)\n",
    "            splits = r.get('https://www.usacycling.org/results/index.php?ajax=1&act=splits&race_id=955427', headers=hdrs)  \n",
    "    else:\n",
    "        print('No event: {}'.format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parses results table\n",
    "#race\n",
    "rm = json.loads(results.text)['message']\n",
    "r = BeautifulSoup(sm, 'html.parser')\n",
    "# Header\n",
    "for h in r.find_all('div', attrs={'class':\"tablecell header\"}):\n",
    "    if len(h.get_text()) > 1:\n",
    "        print(h.get_text())\n",
    "# Results\n",
    "for h in r.find_all('div', attrs={\"class\":\"tablerow\"}):\n",
    "    print(\"-------------------\")\n",
    "    print(' | '.join(c.get_text() for c in h.find_all('div', attrs={\"class\":\"tablecell results\"})))\n",
    "\n",
    "# x[1].find_all('div')[4].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = BeautifulSoup(splits.text, 'html.parser')\n",
    "for r in s.find_all('tr'):\n",
    "    if 'PlaceNameLap' in r.get_text():\n",
    "        print(' | '.join(c.get_text() for c in r.find_all('th')))\n",
    "    print(' | '.join(c.get_text() for c in r.find_all('td')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splits.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x = race.find_all(id)\n",
    "for l in x.find_all('li'):\n",
    "    print(l.get('id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for a in x.find_all('a'):\n",
    "    print(a.getText())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HDRS = {'User-Agent':'Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)'}\n",
    "r = requests.session()\n",
    "# We have to load this page first or other pages return unauthorized access\n",
    "startpage = r.get('http://www.usacycling.org/events/rr.php', headers=HDRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RequestsCookieJar[Cookie(version=0, name='AWSELB', value='E521D7FD16BBFAC3448EBFA5187939F6FA83E71B4EA5057EC0614B3CB6CE991A30E4A28D14B7FF5296BE5EA73F7B0F7F84785C59D05109DC9D1392CA33F0A658D42B57C9B2', port=None, port_specified=False, domain='www.usacycling.org', domain_specified=False, domain_initial_dot=False, path='/', path_specified=True, secure=False, expires=1453488163, discard=False, comment=None, comment_url=None, rest={}, rfc2109=False), Cookie(version=0, name='PHPSESSID', value='tr346v6eaorcqhjqtbdir3pot5', port=None, port_specified=False, domain='www.usacycling.org', domain_specified=False, domain_initial_dot=False, path='/', path_specified=True, secure=False, expires=None, discard=True, comment=None, comment_url=None, rest={'HttpOnly': None}, rfc2109=False)]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startpage.cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.session()\n",
    "bool(r.cookies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "HDRS = {'User-Agent':'Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)'}\n",
    "r = requests.session()\n",
    "\n",
    "# This is the results page, Need to scrape the columns;\n",
    "# Place, Points, Name, City, State, Time, USAC#, Bib, Team\n",
    "# json is http://www.usacycling.org/results/index.php?ajax=1&act=infoid&info_id=94310\n",
    "raceresults = r.get('http://www.usacycling.org/results/index.php?year=2016&id=2', headers=HDRS)\n",
    "#race = BeautifulSoup(raceresults.text, 'html.parser')\n",
    "\n",
    "def get_event_list(session, year):\n",
    "    \"\"\"\n",
    "\n",
    "    :param year:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    eventspage = r.get(\"http://www.usacycling.org/events/?zipcode=80439&radius=50000&race=&fyear=\" + str(year) + \"&rrfilter=rr\" , headers=HDRS)\n",
    "    soup = BeautifulSoup(eventspage.text, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "s = get_event_list(r, 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://penvelo.org/secondary/events.html\n",
      "http://kingsportuci.wordpress.com/\n",
      "http://www.msgcross.com/wordpress/\n",
      "http://localbikeracing.com\n",
      "http://www.miamimasters.com\n",
      "http://www.facebook.com/events/1656904247892205/\n",
      "http://www.nccyclocross.com\n",
      "http://www.usacycling.org/2016/16cxnationals\n",
      "http://www.usacycling.org/2016/16cxnationals\n",
      "http://rapidcyclingracing.com\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-39b5ebaf8642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m#print(cells[1].find(text = re.compile(\"\\s+\\d{2}/\\d{2}/\\d{4}\")))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#print(cells[1].find('a', href=True, text='Event Flyer')['href'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcells\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Event Website'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "for row in s.find('table').find_all('tr'):  # for each row (event)\n",
    "    if 'Permit Number:' in row.get_text(): # Skip the header row\n",
    "        cells = row.find_all('td') # rows are devided into 3 columns\n",
    "        #print(cells[1].find('b')) # event Name\n",
    "        #print(cells[1].find(text = re.compile(\"\\s+Permit Number:\\s\\S+\")))\n",
    "        #print(cells[1].find(text = re.compile(\"\\s+\\d{2}/\\d{2}/\\d{4}\")))\n",
    "        #print(cells[1].find('a', href=True, text='Event Flyer')['href']) \n",
    "        print(cells[1].find('a', href=True, text='Event Website')['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** National Rankings Events within 50000 miles of 80439 (200)\r\n",
      "\t\tDisplay event types:\r\n",
      "\t\t\n",
      "\n",
      "AllRoadTrackMountainCyclo-crossCollegiateBMX\n",
      "\n",
      "Upcoming Events\n",
      "Recent (<45 days)All of 2016All of 2015All of 2014All of 2013All of 2012All of 2011All of 2010All of 2009All of 2008All of 2007All of 2006All of 2005All EventsResults & Rankings EventsFun Rides\n",
      "\n",
      "\r\n",
      "\t\t\tEvents shown have agreed to submit results to the National Rankings System, \r\n",
      "\t\t\tto find all permitted events, select 'All Events' in the far right selection box above.\r\n",
      "\t\t\t\n",
      "***  \n",
      "Event Information  \n",
      "Contact Information  \n",
      "Race Type\n"
     ]
    }
   ],
   "source": [
    "\n",
    "row = s.find('table').find('tr')  # Search result row\n",
    "# print('*** {}'.format(row.get_text()))\n",
    "row = row.find_next_sibling() # Column header row\n",
    "# print('*** {}'.format(row.get_text()))\n",
    "# if 'Permit Number:' in row.get_text(): # Skip the header row\n",
    "#     cells = row.find_all('td') # rows are devided into 3 columns\n",
    "#     #print(cells[1].find('b')) # event Name\n",
    "#     print(cells[1].find(text = re.compile(\"\\s+Permit Number:\\s\\S+\")))\n",
    "#     print(cells[1].find(text = re.compile(\"\\s+\\d{2}/\\d{2}/\\d{4}\")))\n",
    "#     #print(cells[1].find('a', href=True, text='Event Flyer')) \n",
    "#     #print(cells[1].find('a', href=True, text='Event Website'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'t1' : (lambda cell: cell+1)}\n",
    "d['t1'](5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
